{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_pairs(images1,images2):\n",
    "    # images1 : list of images (each image is a tensor)\n",
    "    # images2 : list of images (each image is a tensor)\n",
    "    # scores_net (optional) : network similarity score for each pair\n",
    "    # scores_people (optional) : human similarity score for each pair\n",
    "    npairs = images1.size()[0]\n",
    "    assert images2.size()[0] == npairs\n",
    "    for i in range(npairs):\n",
    "        ax = plt.subplot(npairs, 1, i+1)\n",
    "        imshow(utils.make_grid([images1[i], images2[i]]))\n",
    "        mytitle = ''\n",
    "        if len(scores_net)>0:\n",
    "            mytitle += 'net %.2f, ' % scores_net[i] \n",
    "        if len(scores_people)>0:\n",
    "            mytitle += 'human. %.2f' % scores_people[i]\n",
    "        if mytitle:\n",
    "            plt.title(mytitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images1_digit8,images2_digit8 = get_random_subset(digit_select=8, npairs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0de591c0e630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimages2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplot_image_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimages2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-baba208784a1>\u001b[0m in \u001b[0;36mplot_image_pairs\u001b[0;34m(images1, images2)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# scores_net (optional) : network similarity score for each pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# scores_people (optional) : human similarity score for each pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mimages2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnpairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'size'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 288x2880 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = [\"Bobolink_0043\", \"Bobolink_0047\", \"Bobolink_0097\",\"Hooded_Warbler_0001\",\"Hooded_Warbler_0011\", \"Hooded_Warbler_0112\", \"Indigo_Bunting_002\",\"Indigo_Bunting_0025\", \"Indigo_Bunting_0078\",\"Marsh_Wren_0018\", \"Marsh_Wren_0022\", \"Marsh_Wren_0118\", \"Painted_Bunting_0005\", \"Painted_Bunting_0025\", \"Painted_Bunting_0099\", \"Shiny_Cowbird_0047\", \"Shiny_Cowbird_0064\", \"Shiny_Cowbird_0082\"]\n",
    "# pytorch provides a function to convert PIL images to tensors.\n",
    "pil2tensor = transforms.ToTensor()\n",
    "tensor2pil = transforms.ToPILImage()\n",
    "\n",
    "# Read the image from file. Assuming it is in the same directory.\n",
    "pil_image = Image.open(images[0] + \".jpg\")\n",
    "rgb_image = pil2tensor(pil_image)\n",
    "# todo: loop through all of them\n",
    "images1 = images[0]\n",
    "images2 = images[1]\n",
    "plt.figure(1,figsize=(4,40))\n",
    "plot_image_pairs(images1,images2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
